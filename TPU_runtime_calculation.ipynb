{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPU_runtime_calculation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18yDq3x2hTCE",
        "outputId": "48ba1cbc-61f4-4e39-9113-4dba9a1fa7ce"
      },
      "source": [
        "%pylab inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEOJPx2jhTFF"
      },
      "source": [
        "#Load modules\n",
        "\n",
        "import keras,cv2,os\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
        "from keras.layers import Conv2D, MaxPool2D\n",
        "\n",
        "#from tqdm import tqdm_notebook,trange\n",
        "import matplotlib.pyplot as plt\n",
        "import gc #garbage collection save all the RAM \n",
        "import numpy as np\n",
        "import numpy \n",
        "import pandas as pd\n",
        "from glob import glob \n",
        "import os\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "import io\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "TROQg622hTIR",
        "outputId": "68c1b887-e536-4526-8cad-ef131644f07f"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cf46e09d-eac4-48f1-8710-95517c6bb825\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cf46e09d-eac4-48f1-8710-95517c6bb825\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX8334dDhTMm",
        "outputId": "ad291fa7-6ca5-42d0-b0de-7a140a900db6"
      },
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/e7/3bac01547d2ed3d308ac92a0878fbdb0ed0f3d41fb1906c319ccbba1bfbc/kaggle-1.5.12.tar.gz (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30kB 11.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-cp37-none-any.whl size=73053 sha256=93e8385111c82971304738340b34b2d2baf6a022fb1d219149983b64fdb2ebcf\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/6a/26/d30b7499ff85a4a4593377a87ecf55f7d08af42f0de9b60303\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zINogKREhTPZ",
        "outputId": "673057ef-5e2d-4d43-d4df-47d4e602f060"
      },
      "source": [
        "!kaggle competitions download -c histopathologic-cancer-detection"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading histopathologic-cancer-detection.zip to /content\n",
            "100% 6.30G/6.31G [01:28<00:00, 45.1MB/s]\n",
            "100% 6.31G/6.31G [01:28<00:00, 76.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_ZeRFm9iFJK"
      },
      "source": [
        "!mkdir /content/cancerdata\n",
        "!unzip -qq histopathologic-cancer-detection.zip -d /content/cancerdata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yawNn0PJiFPo"
      },
      "source": [
        "import glob\n",
        "paths_train = [os.path.basename(x) for x in glob.glob(\"/content/cancerdata/train/*.tif\")]\n",
        "paths_test = [os.path.basename(x) for x in glob.glob(\"/content/cancerdata/test/*.tif\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyeXp8Up_uI4",
        "outputId": "fd92c704-b273-49df-f9dc-d1c8111444f0"
      },
      "source": [
        "len(paths_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "220025"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDf4pm2YiFUi"
      },
      "source": [
        "df_train = pd.read_csv('/content/cancerdata/train_labels.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdxjkNDb_2Zf",
        "outputId": "1a91f6b7-518c-47e1-e5bb-eec38fcd2ad0"
      },
      "source": [
        "len(df_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "220025"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jCbzm2ziFYQ"
      },
      "source": [
        "full_train_df = df_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jig6MHOsiFgj"
      },
      "source": [
        "path = ''\n",
        "train_path = paths_train\n",
        "test_path = paths_test\n",
        "\n",
        "df = pd.DataFrame({'path': (train_path)}) \n",
        "df['id'] = df.path.map(lambda x: x.split(\".\")[0]) # file names \n",
        "labels = df_train \n",
        "df = df.merge(labels, on = \"id\") # merge labels and filepaths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9viKKcSiFlg"
      },
      "source": [
        "# Just selected top 1000 for trail run \n",
        "df = df.head(500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMCFPJqyiFur"
      },
      "source": [
        "def imge_nump(y):\n",
        "    pil_image=Image.open('/content/cancerdata/train/'+y) \n",
        "    numpy_image=numpy.array(pil_image)\n",
        "    numpy_image = tf.keras.preprocessing.image.array_to_img(numpy_image)\n",
        "    return numpy_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkRo1FHdjCvr"
      },
      "source": [
        "df['image'] = df.apply(lambda x: imge_nump(x['path']), axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeUzuR_yjC50",
        "outputId": "2f40d7e4-2daf-4af4-c964-2f480ff46547"
      },
      "source": [
        "input_images = np.stack(list(df.image), axis = 0)\n",
        "input_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 96, 96, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPQumJn4jC-K"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.utils import np_utils\n",
        "\n",
        "\n",
        "train_fraction = 0.8\n",
        "\n",
        "encoder = LabelBinarizer()\n",
        "y = encoder.fit_transform(df.label)\n",
        "x = input_images\n",
        "\n",
        "train_tensors, test_tensors, train_targets, test_targets = train_test_split(x, y, train_size = train_fraction, random_state = 42)\n",
        "\n",
        "val_size = int(0.5*len(test_tensors))\n",
        "\n",
        "val_tensors = test_tensors[:val_size]\n",
        "val_targets = test_targets[:val_size]\n",
        "test_tensors = test_tensors[val_size:]\n",
        "test_targets = test_targets[val_size:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbvaUnH0ztxj"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 5)\n",
        "checkpointer = ModelCheckpoint(filepath='weights.hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = (96, 96, 3)))\n",
        "model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling2D(pool_size = 3)) \n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu')) \n",
        "model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu')) \n",
        "model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling2D(pool_size = 3)) \n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling2D(pool_size = 3))\n",
        "\n",
        "model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'elu'))\n",
        "model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'elu'))\n",
        "model.add(Conv2D(filters = 256, kernel_size = 3, padding = 'same', activation = 'elu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation = 'sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g8sJUnkV78W"
      },
      "source": [
        "def auc(y_true, y_pred):   \n",
        "    ptas = tf.stack([binary_PTA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
        "    pfas = tf.stack([binary_PFA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
        "    pfas = tf.concat([tf.ones((1,)) ,pfas],axis=0)\n",
        "    binSizes = -(pfas[1:]-pfas[:-1])\n",
        "    s = ptas*binSizes\n",
        "    return K.sum(s, axis=0)\n",
        "\n",
        "#------------------------------------------------------\n",
        "#------------------------------------------------------\n",
        "# PFA, prob false alert for binary classifier\n",
        "def binary_PFA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
        "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
        "    # N = total number of negative labels\n",
        "    N = K.sum(1 - y_true)\n",
        "    # FP = total number of false alerts, alerts from the negative class labels\n",
        "    FP = K.sum(y_pred - y_pred * y_true)\n",
        "    return FP/N\n",
        "\n",
        "#------------------------------------------------------\n",
        "#------------------------------------------------------\n",
        "\n",
        "# PTA prob true alerts for binary classifier\n",
        "def binary_PTA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
        "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
        "    # P = total number of positive labels\n",
        "    P = K.sum(y_true)\n",
        "    # TP = total number of correct alerts, alerts from the positive class labels\n",
        "    TP = K.sum(y_pred * y_true)\n",
        "    return TP/P\n",
        "\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# sgd = SGD(lr = 0.0001, momentum = 0.9)\n",
        "model.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "epochs = 15\n",
        "model.fit(train_tensors, train_targets, validation_data=(val_tensors, val_targets),epochs=epochs, batch_size=80, verbose=1, callbacks = [early_stopping, checkpointer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2Ed0ayfApxS"
      },
      "source": [
        "pil_image_pred=Image.open('/content/cancerdata/test/000270442cc15af719583a8172c87cd2bd9c7746.tif')\n",
        "numpy_image_pred=numpy.array(pil_image_pred)\n",
        "numpy_image_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vigHz4-sBnc0",
        "outputId": "76089634-a778-4c47-978a-0985a4fdff40"
      },
      "source": [
        "predicted_sample =  [model.predict(np.expand_dims(numpy_image_pred, axis=0))[0][0]]\n",
        "predicted_sample"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.17105281]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND7qr3P4FJ1y",
        "outputId": "ccb08600-3b70-4227-96c6-4c016cc7d3ca"
      },
      "source": [
        "test_tensors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 96, 96, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm8TTigsjDJi",
        "outputId": "875f4ac8-463a-4128-c820-cda2f04e80d2"
      },
      "source": [
        "model.load_weights('weights.hdf5')\n",
        "\n",
        "cancer_predictions =  [model.predict(np.expand_dims(tensor, axis=0))[0][0] for tensor in test_tensors]\n",
        "\n",
        "test_accuracy = 100*np.sum(np.round(cancer_predictions).astype('int32')==test_targets.flatten())/len(cancer_predictions)\n",
        "print('Test accuracy: %.4f%%' % test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 72.0000%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "497KOZhaiFxx",
        "outputId": "2b811688-9970-4a7c-9378-7be821c22da3"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "score = roc_auc_score(np.round(cancer_predictions).astype('int32'), test_targets)\n",
        "score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7192118226600985"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoHvJaoRf6Z1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a676e1c-1798-40d4-d618-f2623605e119"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Distribution strategies\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "\n",
        "# MNIST model\n",
        "def create_model():\n",
        "  return tf.keras.Sequential(\n",
        "      [tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "       tf.keras.layers.Flatten(),\n",
        "       tf.keras.layers.Dense(128, activation='relu'),\n",
        "       tf.keras.layers.Dense(10)])\n",
        "\n",
        "# Input datasets\n",
        "def get_dataset(batch_size=200):\n",
        "  datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True,\n",
        "                             try_gcs=True)\n",
        "  mnist_train, mnist_test = datasets['train'], datasets['test']\n",
        "\n",
        "  def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255.0\n",
        "\n",
        "    return image, label\n",
        "\n",
        "  train_dataset = mnist_train.map(scale).shuffle(10000).batch(batch_size)\n",
        "  test_dataset = mnist_test.map(scale).batch(batch_size)\n",
        "\n",
        "  return train_dataset, test_dataset\n",
        "\n",
        "# Create and train a model\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "train_dataset, test_dataset = get_dataset()\n",
        "\n",
        "model.fit(train_dataset,\n",
        "          epochs=5,\n",
        "          validation_data=test_dataset,steps_per_epoch=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/5\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 0.1073 - sparse_categorical_accuracy: 0.9678 - val_loss: 0.0851 - val_sparse_categorical_accuracy: 0.9740\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7a4af9aa90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URVnfWtz1dxH"
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_host(resolver.master())\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "\n",
        "with strategy.scope():\n",
        "  # model = create_model()\n",
        "  # model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "  #               metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "  # model.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  tf.random.set_seed(42)\n",
        "\n",
        "  early_stopping = EarlyStopping(monitor = 'val_loss', patience = 5)\n",
        "  checkpointer = ModelCheckpoint(filepath='weights.hdf5', \n",
        "                                verbose=1, save_best_only=True)\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = (96, 96, 3)))\n",
        "  model.add(tf.keras.layers.Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size = 3)) \n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu')) \n",
        "  model.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu')) \n",
        "  model.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size = 3)) \n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size = 3))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'elu'))\n",
        "  model.add(tf.keras.layers.Conv2D(filters = 256, kernel_size = 3, padding = 'same', activation = 'elu'))\n",
        "\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n",
        "  model.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NikBmej9kFSc"
      },
      "source": [
        "epochs = 15\n",
        "model.fit(train_tensors, train_targets, validation_data=(val_tensors, val_targets),epochs=epochs, batch_size=80, verbose=1, callbacks = [early_stopping, checkpointer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYrf9V-GGWQ4"
      },
      "source": [
        "model.fit_generator(train_gen, steps_per_epoch=train_steps, \n",
        "                    validation_data=val_gen,\n",
        "                    validation_steps=val_steps,\n",
        "                    epochs=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQb7Evgr07PA"
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zc-GvxNe1H3V"
      },
      "source": [
        "train_tensors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5PfrNEG2Xrr"
      },
      "source": [
        "def get_dataset(batch_size=200):\n",
        "  datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True,\n",
        "                             try_gcs=True)\n",
        "  mnist_train, mnist_test = datasets['train'], datasets['test']\n",
        "\n",
        "  def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255.0\n",
        "\n",
        "    return image, label\n",
        "\n",
        "  train_dataset = mnist_train.map(scale).shuffle(10000).batch(batch_size)\n",
        "  test_dataset = mnist_test.map(scale).batch(batch_size)\n",
        "\n",
        "  return train_dataset, test_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F05sgtmx2Z4v"
      },
      "source": [
        "datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True,try_gcs=True)\n",
        "mnist_train, mnist_test = datasets['train'], datasets['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frKFsMnQ24O2"
      },
      "source": [
        "mnist_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikRSwoSv7k_L"
      },
      "source": [
        "train = tf.keras.preprocessing.image_dataset_from_directory(directory = '/content/cancerdata/test',\n",
        "                                                            labels = list(df_train['label']),\n",
        "                                                            label_mode='int',\n",
        "                                                            image_size=(96,96),\n",
        "                                                            batch_size=32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk6PaqMAGfY9"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnkeoqsY8Csv"
      },
      "source": [
        "list(df_train['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiDWaW388bw5"
      },
      "source": [
        "df_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9fjV9XYHBAx"
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "img = load_img('/content/cancerdata/test/000270442cc15af719583a8172c87cd2bd9c7746.tif')\n",
        "print(type(img))         # prints PIL.Image.Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKwqRriAPQnM"
      },
      "source": [
        "df = pd.read_csv('/content/cancerdata/train_labels.csv')\n",
        "df['id']=df['id'].apply(lambda x: x+'.tif')\n",
        "df['label']=df['label'].apply(lambda x: str(x))\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "       # horizontal_flip=True,\n",
        "       #vertical_flip=True,\n",
        "       #brightness_range=[0.5, 1.5],\n",
        "       #fill_mode='reflect',                               \n",
        "        #rotation_range=15,\n",
        "        rescale=1./255,\n",
        "        #shear_range=0.2,\n",
        "        #zoom_range=0.2\n",
        "        validation_split=0.15\n",
        "    \n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_path = '/content/cancerdata/train'\n",
        "valid_path = '/content/cancerdata/train'\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "                dataframe=df,\n",
        "                directory=train_path,\n",
        "                x_col = 'id',\n",
        "                y_col = 'label',\n",
        "                has_ext=False,\n",
        "                subset='training',\n",
        "                target_size=(96, 96),\n",
        "                batch_size=64,\n",
        "                class_mode='binary'\n",
        "                )\n",
        "\n",
        "validation_generator = train_datagen.flow_from_dataframe(\n",
        "                dataframe=df,\n",
        "                directory=valid_path,\n",
        "                x_col = 'id',\n",
        "                y_col = 'label',\n",
        "                has_ext=False,\n",
        "                subset='validation', # This is the trick to properly separate train and validation dataset\n",
        "                target_size=(96, 96),\n",
        "                batch_size=64,\n",
        "                shuffle=False,\n",
        "                class_mode='binary'\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykUNjNVpURLI"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = (96, 96, 3)))\n",
        "model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling2D(pool_size = 3))\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling2D(pool_size = 3))\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling2D(pool_size = 3))\n",
        "\n",
        "model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'elu'))\n",
        "model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'elu'))\n",
        "model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'elu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ4v8vc0Ul6e"
      },
      "source": [
        "model.fit_generator(\n",
        "                train_generator,\n",
        "                steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                epochs=15,\n",
        "                validation_data=validation_generator,\n",
        "                validation_steps=STEP_SIZE_VALID)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfBTJ70wX_b7"
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(101)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuZ6xCdDYKkR"
      },
      "source": [
        "IMAGE_SIZE = 96\n",
        "IMAGE_CHANNELS = 3\n",
        "\n",
        "SAMPLE_SIZE = 80000 # the number of images we use from each of the two classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dR23HS-YMJ8"
      },
      "source": [
        "df_data = pd.read_csv('/content/cancerdata/train_labels.csv')\n",
        "\n",
        "# removing this image because it caused a training error previously\n",
        "df_data[df_data['id'] != 'dd6dfed324f9fcb6f93f46f32fc800f2ec196be2']\n",
        "\n",
        "# removing this image because it's black\n",
        "df_data[df_data['id'] != '9369c7278ec8bcc6c880d99194de09fc2bd4efbe']\n",
        "\n",
        "IMAGE_PATH = '/content/cancerdata/train/'\n",
        "# train_test_split\n",
        "\n",
        "# stratify=y creates a balanced validation set.\n",
        "y = df_data['label']\n",
        "\n",
        "df_train, df_val = train_test_split(df_data, test_size=0.10, random_state=101, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doWJwM70Zc-L"
      },
      "source": [
        "base_dir = '/content/cancerdata/base_dir'\n",
        "os.mkdir(base_dir)\n",
        "\n",
        "train_dir = os.path.join(base_dir, '/content/cancerdata/train_dir')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "# val_dir\n",
        "val_dir = os.path.join(base_dir, '/content/cancerdata/val_dir')\n",
        "os.mkdir(val_dir)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiGbkQqlYhws"
      },
      "source": [
        "\n",
        "# [CREATE FOLDERS INSIDE THE TRAIN AND VALIDATION FOLDERS]\n",
        "# Inside each folder we create seperate folders for each class\n",
        "\n",
        "# create new folders inside train_dir\n",
        "no_tumor_tissue = os.path.join(train_dir, 'a_no_tumor_tissue')\n",
        "os.mkdir(no_tumor_tissue)\n",
        "has_tumor_tissue = os.path.join(train_dir, 'b_has_tumor_tissue')\n",
        "os.mkdir(has_tumor_tissue)\n",
        "\n",
        "# create new folders inside val_dir\n",
        "no_tumor_tissue = os.path.join(val_dir, 'a_no_tumor_tissue')\n",
        "os.mkdir(no_tumor_tissue)\n",
        "has_tumor_tissue = os.path.join(val_dir, 'b_has_tumor_tissue')\n",
        "os.mkdir(has_tumor_tissue)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7X8Su_Narjw"
      },
      "source": [
        "# Set the id as the index in df_data\n",
        "df_data.set_index('id', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eFKlVLQa0GK"
      },
      "source": [
        "# Get a list of train and val images\n",
        "train_list = list(df_train['id'])\n",
        "val_list = list(df_val['id'])\n",
        "\n",
        "\n",
        "\n",
        "# Transfer the train images\n",
        "\n",
        "for image in train_list:\n",
        "    \n",
        "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
        "    fname = image + '.tif'\n",
        "    # get the label for a certain image\n",
        "    target = df_data.loc[image,'label']\n",
        "    \n",
        "    # these must match the folder names\n",
        "    if target == 0:\n",
        "        label = 'a_no_tumor_tissue'\n",
        "    if target == 1:\n",
        "        label = 'b_has_tumor_tissue'\n",
        "    \n",
        "    # source path to image\n",
        "    src = os.path.join('/content/cancerdata/train', fname)\n",
        "    # destination path to image\n",
        "    dst = os.path.join(train_dir, label, fname)\n",
        "    # copy the image from the source to the destination\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "\n",
        "# Transfer the val images\n",
        "\n",
        "for image in val_list:\n",
        "    \n",
        "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
        "    fname = image + '.tif'\n",
        "    # get the label for a certain image\n",
        "    target = df_data.loc[image,'label']\n",
        "    \n",
        "    # these must match the folder names\n",
        "    if target == 0:\n",
        "        label = 'a_no_tumor_tissue'\n",
        "    if target == 1:\n",
        "        label = 'b_has_tumor_tissue'\n",
        "    \n",
        "\n",
        "    # source path to image\n",
        "    src = os.path.join('/content/cancerdata/train', fname)\n",
        "    # destination path to image\n",
        "    dst = os.path.join(val_dir, label, fname)\n",
        "    # copy the image from the source to the destination\n",
        "    shutil.copyfile(src, dst)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6nFDPs6d6Jn"
      },
      "source": [
        "train_path = '/content/cancerdata/train_dir'\n",
        "valid_path = '/content/cancerdata/val_dir'\n",
        "test_path = '/content/cancerdata/test'\n",
        "\n",
        "num_train_samples = len(df_train)\n",
        "num_val_samples = len(df_val)\n",
        "train_batch_size = 10\n",
        "val_batch_size = 10\n",
        "\n",
        "\n",
        "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
        "val_steps = np.ceil(num_val_samples / val_batch_size)\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "train_gen = datagen.flow_from_directory(train_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=train_batch_size,\n",
        "                                        class_mode='categorical')\n",
        "\n",
        "val_gen = datagen.flow_from_directory(valid_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=val_batch_size,\n",
        "                                        class_mode='categorical')\n",
        "\n",
        "# Note: shuffle=False causes the test dataset to not be shuffled\n",
        "test_gen = datagen.flow_from_directory(valid_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=1,\n",
        "                                        class_mode='categorical',\n",
        "                                        shuffle=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fri1BEtafj_Y"
      },
      "source": [
        "kernel_size = (3,3)\n",
        "pool_size= (2,2)\n",
        "first_filters = 32\n",
        "second_filters = 64\n",
        "third_filters = 128\n",
        "\n",
        "dropout_conv = 0.3\n",
        "dropout_dense = 0.3\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (96, 96, 3)))\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = pool_size)) \n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size = pool_size))\n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size = pool_size))\n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(dropout_dense))\n",
        "model.add(Dense(2, activation = \"softmax\"))\n",
        "\n",
        "model.compile(Adam(lr=0.0001), loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "filepath = \"model.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n",
        "                             save_best_only=True, mode='max')\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, \n",
        "                                   verbose=1, mode='max', min_lr=0.00001)\n",
        "                              \n",
        "                              \n",
        "callbacks_list = [checkpoint, reduce_lr]\n",
        "\n",
        "history = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n",
        "                    validation_data=val_gen,\n",
        "                    validation_steps=val_steps,\n",
        "                    epochs=15, verbose=1,\n",
        "                   callbacks=callbacks_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}